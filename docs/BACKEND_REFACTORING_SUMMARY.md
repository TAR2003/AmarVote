# Backend Refactoring - Queue-Based Processing

## Problem Identified

The backend was doing ALL the processing work for:
- Tally creation
- Partial decryption
- Compensated decryption  
- Combine decryption shares

Instead of just fetching IDs and sending them to workers, the backend was:
1. Fetching IDs
2. Loading all related data from database
3. Calling ElectionGuard microservice
4. Storing results in database

This defeats the purpose of the worker architecture!

## Solution Implemented

### What the Backend Should Do (Fixed ‚úÖ)

**Backend's ONLY job:**
1. Receive request from client
2. Fetch IDs (ballot IDs or election_center_ids)
3. Create job record in database
4. Publish ID chunks to RabbitMQ queue
5. Return job ID immediately to client

**Worker's job (Already implemented, now being used properly):**
1. Pick up one chunk ID from queue
2. Fetch related data from database using that ID
3. Call ElectionGuard microservice with the data
4. Store results in database
5. Mark chunk as complete

## Files Created

### 1. DecryptionQueueService.java
- Validates guardian and tally existence
- Decrypts guardian credentials
- Publishes election_center_ids to decryption queue
- Returns job ID immediately

### 2. CompensatedDecryptionQueueService.java
- Finds missing guardians
- Publishes (chunk, source_guardian, missing_guardian) combinations to queue
- Returns job IDs immediately

### 3. CombineDecryptionQueueService.java
- Validates election exists
- Publishes election_center_ids to combine queue
- Returns job ID immediately

## Files Modified

### 1. QueuePublisherService.java
Added:
- `publishCompensatedDecryptionJob()` method

### 2. ElectionController.java
Updated endpoints to use queue services:
- `/api/create-partial-decryption` ‚Üí uses `DecryptionQueueService`
- `/api/guardian/initiate-decryption` ‚Üí uses `DecryptionQueueService`
- `/api/initiate-combine` ‚Üí uses `CombineDecryptionQueueService`
- `/api/combine-partial-decryption` ‚Üí uses `CombineDecryptionQueueService`

All endpoints now return `JobResponse` with:
- `jobId`: UUID for tracking
- `totalChunks`: Number of chunks to process
- `status`: "IN_PROGRESS"
- `pollUrl`: "/api/jobs/{jobId}/status" for checking progress

## Architecture Flow (Fixed)

### Before (‚ùå Wrong)
```
Client ‚Üí Backend (fetch IDs, load data, call microservice, store results) ‚Üí Response
         ‚Üì (ALL processing done here - SLOW!)
         Returns after everything is done
```

### After (‚úÖ Correct)
```
Client ‚Üí Backend (fetch IDs only) ‚Üí RabbitMQ ‚Üí Worker (load data, call microservice, store)
         ‚Üì                                        ‚Üì
         Returns job ID immediately               Processes in background
         
Client can poll: /api/jobs/{jobId}/status for progress
```

## Operation Flows

### 1. Tally Creation (Already fixed)
Backend: Fetch ballot IDs ‚Üí Publish to queue ‚Üí Return job ID
Worker: Load ballots ‚Üí Call ElectionGuard ‚Üí Store tally

### 2. Partial Decryption (Fixed ‚úÖ)
Backend: Fetch election_center_ids + Decrypt credentials ‚Üí Publish to queue ‚Üí Return job ID
Worker: Load submitted ballots ‚Üí Call ElectionGuard ‚Üí Store partial decryption

### 3. Compensated Decryption (Fixed ‚úÖ)
Backend: Fetch election_center_ids + Find missing guardians ‚Üí Publish to queue ‚Üí Return job IDs
Worker: Load ballots + guardian data ‚Üí Call ElectionGuard ‚Üí Store compensated shares

### 4. Combine Decryption (Fixed ‚úÖ)
Backend: Fetch election_center_ids ‚Üí Publish to queue ‚Üí Return job ID
Worker: Load partial + compensated decryptions ‚Üí Call ElectionGuard ‚Üí Store final results

## What Workers Do (No changes needed - already correct)

### TallyWorker
- ‚úÖ Receives chunk ID
- ‚úÖ Loads ballots for that chunk
- ‚úÖ Calls ElectionGuard microservice
- ‚úÖ Stores encrypted tally

### DecryptionWorker  
- ‚úÖ Receives chunk ID + guardian ID
- ‚úÖ Loads submitted ballots for that chunk
- ‚úÖ Calls ElectionGuard microservice
- ‚úÖ Stores partial decryption

### CompensatedDecryptionWorker
- ‚úÖ Receives chunk ID + source guardian + missing guardian
- ‚úÖ Loads ballots and guardian data
- ‚úÖ Calls ElectionGuard microservice
- ‚úÖ Stores compensated share

### CombineDecryptionWorker
- ‚úÖ Receives chunk ID
- ‚úÖ Loads partial and compensated decryptions
- ‚úÖ Calls ElectionGuard microservice
- ‚úÖ Stores final decrypted result

## Benefits

1. **Memory Efficient**: Backend uses minimal memory (just fetching IDs)
2. **Scalable**: Can add more workers by scaling backend containers
3. **Fast Response**: Client gets immediate response with job ID
4. **Fault Tolerant**: Failed chunks automatically retry
5. **Horizontal Scaling**: `docker-compose up -d --scale backend=10`

## Testing Checklist

- [ ] Tally creation returns job ID immediately
- [ ] Partial decryption returns job ID immediately
- [ ] Compensated decryption returns job IDs immediately
- [ ] Combine decryption returns job ID immediately
- [ ] Workers process chunks in background
- [ ] Check logs: Backend should only show "Fetching IDs" and "Publishing to queue"
- [ ] Workers should show "Loading data", "Calling microservice", "Storing results"
- [ ] Poll /api/jobs/{jobId}/status shows progress
- [ ] All operations complete successfully end-to-end

## Backend Log Pattern (Should Look Like This)

```
‚úÖ Backend:
- "=== Creating Partial Decryption (Queue Mode) ==="
- "Found 2000 chunks"
- "‚úÖ Successfully decrypted guardian credentials"
- "üì§ Publishing job to queue"
- "‚úÖ Published job: uuid-123"
- Returns in < 1 second

‚úÖ Worker (background):
- "=== Decryption Worker Processing Chunk ==="
- "‚úÖ Loaded 50 submitted ballots"
- "‚è≥ Calling ElectionGuard microservice..."
- "‚úÖ Stored partial decryption"
- "‚úÖ Chunk completed successfully"
- Processes over minutes/hours
```

## What NOT to See in Backend Logs

‚ùå "Processing chunk 1 of 2000..."
‚ùå "Calling ElectionGuard microservice..."
‚ùå "Storing partial decryption..."
‚ùå Backend taking minutes to respond

If you see these in backend logs, it means backend is still doing the work!

## Summary

‚úÖ Backend now only fetches IDs and publishes to queue
‚úÖ Workers do all the heavy processing
‚úÖ All operations (tally, partial decryption, compensated, combine) use queue system
‚úÖ Client gets immediate response with job ID
‚úÖ Can scale horizontally by adding more workers
